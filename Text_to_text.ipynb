{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"I think it's highly unlikely that Tom will be allowed to keep the gold that he found.\",\n",
       "  '[start] আমার মনে হয় টম যে সোনা পেয়েছে সেটা তার কাছে রাখতে দেওয়া হবে এমন সম্ভাবনা খুব কম। [end]'),\n",
       " (\"Tom told Mary that he was going to kill himself, but he didn't have the courage to do it.\",\n",
       "  '[start] টম মেরিকে বললো যে ও নিজেকে হত্যা করতে চলেছিলো, কিন্ত তা করার মতো সাহস ছিলো না। [end]'),\n",
       " (\"Tom's an irritating person to work with because he'll never admit it when he's made a mistake.\",\n",
       "  '[start] টমের সঙ্গে কাজ করা খুব বিরক্তিকর কারণ ও কখনই মেনে নেয় না যে ও ভুল করেছে। [end]'),\n",
       " (\"I thought doing this would be easy, but we've been working all day and we're still not finished.\",\n",
       "  '[start] আমি ভেবেছিলাম এটা করা সহজ হবে, কিন্তু আমরা সারাদিন ধরে কাজ করেছি আর এখনো শেষ করে উঠতে পারিনি। [end]'),\n",
       " ('January, February, March, April, May, June, July, August, September, October, November and December are the twelve months of the year.',\n",
       "  '[start] বছরের বারোটা মাস হলো জানুয়ারি, ফেব্রুয়ারি, মার্চ, এপ্রিল, মে, জুন জুলাই, আগস্ট, সেপ্টেম্বর, অক্টোবর, নভেম্বর আর ডিসেম্বর। [end]')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file = \"./en_bn.txt\"\n",
    "text_pairs = []\n",
    "\n",
    "for line in open(text_file):\n",
    "    eng, spa = line.rstrip().split(\"\\t\")\n",
    "    spa = \"[start] \" + spa + \" [end]\"\n",
    "    text_pairs.append((eng, spa))\n",
    "    \n",
    "text_pairs[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4619 total pairs\n",
      "3235 training pairs\n",
      "692 validation pairs\n",
      "692 test pairs\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
    "\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 15:12:16.295976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-08 15:12:16.296568: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-08 15:12:16.296643: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-08 15:12:16.296709: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-08 15:12:16.296771: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-08 15:12:16.296828: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-08 15:12:16.296883: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-08 15:12:16.296940: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-08 15:12:16.296996: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-09-08 15:12:16.297004: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-08 15:12:16.297554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "\n",
    "eng_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",
    ")\n",
    "spa_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "train_eng_texts = [pair[0] for pair in train_pairs]\n",
    "train_spa_texts = [pair[1] for pair in train_pairs]\n",
    "eng_vectorization.adapt(train_eng_texts)\n",
    "spa_vectorization.adapt(train_spa_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(eng, spa):\n",
    "    eng = eng_vectorization(eng)\n",
    "    spa = spa_vectorization(spa)\n",
    "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": spa[:, :-1],}, spa[:, 1:])\n",
    "\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
      "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 15:12:47.937602: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "latent_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " positional_embedding (Position  (None, None, 256)   3845120     ['encoder_inputs[0][0]']         \n",
      " alEmbedding)                                                                                     \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  (None, None, 256)   3155456     ['positional_embedding[0][0]']   \n",
      " erEncoder)                                                                                       \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, None, 15000)  12959640    ['decoder_inputs[0][0]',         \n",
      "                                                                  'transformer_encoder[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 19,960,216\n",
      "Trainable params: 19,960,216\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "51/51 [==============================] - 33s 592ms/step - loss: 0.2356 - accuracy: 0.8680 - val_loss: 0.9303 - val_accuracy: 0.6071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./en_bn_Translation/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./en_bn_Translation/assets\n",
      "/home/joy/.local/lib/python3.10/site-packages/keras/engine/functional.py:1384: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "/home/joy/.local/lib/python3.10/site-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "epochs = 1  # This should be at least 30 for convergence\n",
    "\n",
    "transformer.summary()\n",
    "transformer.compile(\n",
    "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)\n",
    "modelPath = \"./en_bn_Translation\"\n",
    "transformer.save(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joy/.local/lib/python3.10/site-packages/keras/engine/functional.py:1384: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "\nLayer PositionalEmbedding has arguments ['self', 'sequence_length', 'vocab_size', 'embed_dim']\nin `__init__` and therefore must override `get_config()`.\n\nExample:\n\nclass CustomLayer(keras.layers.Layer):\n    def __init__(self, arg1, arg2):\n        super().__init__()\n        self.arg1 = arg1\n        self.arg2 = arg2\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"arg1\": self.arg1,\n            \"arg2\": self.arg2,\n        })\n        return config",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/joy/PythonCodes/Deep Learning/Text_to_text.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/joy/PythonCodes/Deep%20Learning/Text_to_text.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m modelPath \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39men_bn_Translationxyz.h5\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/joy/PythonCodes/Deep%20Learning/Text_to_text.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m transformer\u001b[39m.\u001b[39;49msave(modelPath, save_format\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mh5\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/base_layer.py:745\u001b[0m, in \u001b[0;36mLayer.get_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[39m# Check that either the only argument in the `__init__` is  `self`,\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[39m# or that `get_config` has been overridden:\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(extra_args) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_config, \u001b[39m'\u001b[39m\u001b[39m_is_default\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 745\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(textwrap\u001b[39m.\u001b[39mdedent(\u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    746\u001b[0m \u001b[39m      Layer \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m has arguments \u001b[39m\u001b[39m{\u001b[39;00mextra_args\u001b[39m}\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[39m      in `__init__` and therefore must override `get_config()`.\u001b[39m\n\u001b[1;32m    748\u001b[0m \n\u001b[1;32m    749\u001b[0m \u001b[39m      Example:\u001b[39m\n\u001b[1;32m    750\u001b[0m \n\u001b[1;32m    751\u001b[0m \u001b[39m      class CustomLayer(keras.layers.Layer):\u001b[39m\n\u001b[1;32m    752\u001b[0m \u001b[39m          def __init__(self, arg1, arg2):\u001b[39m\n\u001b[1;32m    753\u001b[0m \u001b[39m              super().__init__()\u001b[39m\n\u001b[1;32m    754\u001b[0m \u001b[39m              self.arg1 = arg1\u001b[39m\n\u001b[1;32m    755\u001b[0m \u001b[39m              self.arg2 = arg2\u001b[39m\n\u001b[1;32m    756\u001b[0m \n\u001b[1;32m    757\u001b[0m \u001b[39m          def get_config(self):\u001b[39m\n\u001b[1;32m    758\u001b[0m \u001b[39m              config = super().get_config()\u001b[39m\n\u001b[1;32m    759\u001b[0m \u001b[39m              config.update(\u001b[39m\u001b[39m{{\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[39m                  \u001b[39m\u001b[39m\"\u001b[39m\u001b[39marg1\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: self.arg1,\u001b[39m\n\u001b[1;32m    761\u001b[0m \u001b[39m                  \u001b[39m\u001b[39m\"\u001b[39m\u001b[39marg2\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: self.arg2,\u001b[39m\n\u001b[1;32m    762\u001b[0m \u001b[39m              \u001b[39m\u001b[39m}}\u001b[39;00m\u001b[39m)\u001b[39m\n\u001b[1;32m    763\u001b[0m \u001b[39m              return config\u001b[39m\u001b[39m\"\"\"\u001b[39m))\n\u001b[1;32m    765\u001b[0m \u001b[39mreturn\u001b[39;00m config\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: \nLayer PositionalEmbedding has arguments ['self', 'sequence_length', 'vocab_size', 'embed_dim']\nin `__init__` and therefore must override `get_config()`.\n\nExample:\n\nclass CustomLayer(keras.layers.Layer):\n    def __init__(self, arg1, arg2):\n        super().__init__()\n        self.arg1 = arg1\n        self.arg2 = arg2\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"arg1\": self.arg1,\n            \"arg2\": self.arg2,\n        })\n        return config"
     ]
    }
   ],
   "source": [
    "modelPath = \"en_bn_Translationxyz\"\n",
    "transformer.save(modelPath, save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We heard Tom was in trouble. [start] আমরা মনে হয় ভেতরে আমরা ভেতরে আছি। [end]\n",
      "Don't sing. [start] গাও না। [end]\n",
      "Is your watch correct? [start] তোমার বাবার বয়স কত [end]\n",
      "They need friends. [start] ওদের বন্ধু লাগবে। [end]\n",
      "Can it be phrased in another way? [start] এটাকে কি অন্য ভাষায় প্রকাশ করা যায় [end]\n",
      "What is your phone number? [start] আপনার ফোন নাম্বারটা কী [end]\n",
      "Tom said Mary had given him permission to leave early. [start] টম মেরিকে বললো যে মেরি কোথায় ছিলো। [end]\n",
      "My wrist hurts. [start] আমার গলা ব্যাথা করছে। [end]\n",
      "Don't leave me alone. [start] আমাকে একলা ফেলে রেখে যেও না। [end]\n",
      "I would have liked to come with you, but I didn't have time. [start] আমি তোমাদের সাথে যেতে পারতাম কিন্তু আমার সময় ছিল না। [end]\n",
      "Mistakes happen. [start] ও খাচ্ছে। [end]\n",
      "They don't care. [start] ওনারা পরোয়া করে না। [end]\n",
      "I watch television. [start] আমি দেখে তো সস্তা মনে হয়েছিল। [end]\n",
      "I'll scream. [start] আমি চিৎকার করবো। [end]\n",
      "How long does the trip take? [start] প্রবেশমূল্য কত [end]\n",
      "What time does the next train leave for Tokyo? [start] ট্রেনটা কটার সময় ছাড়ে [end]\n",
      "Tom wanted you to have this. [start] টম চেয়েছিল তুই এটা নিস। [end]\n",
      "Can I change the channel? [start] আমি কি ক্রেডিট কার্ড নেন [end]\n",
      "I'm still your friend. [start] আমি এখনো তোমাদের বন্ধু আছি। [end]\n",
      "I didn't hit anybody. [start] আমি কাউকে ধাক্কা মারিনি। [end]\n",
      "Those roses are very beautiful. [start] তারা খুব একটি সমাধান খুঁজে হয়ে গেলো। [end]\n",
      "You are in my way. [start] আপনি আমার রাস্তা আটকে রেখেছিস। [end]\n",
      "How are you? Did you have a good trip? [start] কেমন আছো যাত্রা ভালো ছিল তো [end]\n",
      "I'll call them tomorrow when I come back. [start] আমি কাল সকালে ফিরে আসবো। [end]\n",
      "Stay at home. [start] বাড়িতে কেউ আছেন [end]\n",
      "Those roses are very beautiful. [start] তারা খুব একটি সমাধান খুঁজে হয়ে গেলো। [end]\n",
      "Who wants to talk to me? [start] কে আমার সাথে কথা বলতে চায় [end]\n",
      "Do you eat meat? [start] আপনি কি মাংস খান [end]\n",
      "They won. [start] ওনারা জিতলেন। [end]\n",
      "You may choose whichever you want. [start] তোমার যেটা ইচ্ছা সেটা বেছে নিতে পারেন। [end]\n"
     ]
    }
   ],
   "source": [
    "spa_vocab = spa_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(30):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    translated = decode_sequence(input_sentence)\n",
    "    print(input_sentence,translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start] আমি আপনাকে ঘৃণা করি। [end]\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"I hate you\"\n",
    "translation = decode_sequence(input_sentence)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"transformer_decoder\" (type TransformerDecoder).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (4 total):\n    * <tf.Tensor 'inputs:0' shape=(None, None, 256) dtype=float32>\n    * <tf.Tensor 'encoder_outputs:0' shape=(None, None, 256) dtype=float32>\n    * None\n    * False\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 2 option(s):\n\nOption 1:\n  Positional arguments (4 total):\n    * TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs')\n    * TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='encoder_outputs')\n    * TensorSpec(shape=(None, None), dtype=tf.bool, name='mask')\n    * False\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (4 total):\n    * TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs')\n    * TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='encoder_outputs')\n    * TensorSpec(shape=(None, None), dtype=tf.bool, name='mask')\n    * True\n  Keyword arguments: {}\n\nCall arguments received by layer \"transformer_decoder\" (type TransformerDecoder):\n  • args=('tf.Tensor(shape=(None, None, 256), dtype=float32)',)\n  • kwargs={'encoder_outputs': 'tf.Tensor(shape=(None, None, 256), dtype=float32)', 'training': 'False'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/joy/PythonCodes/Deep Learning/Text_to_text.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/joy/PythonCodes/Deep%20Learning/Text_to_text.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/joy/PythonCodes/Deep%20Learning/Text_to_text.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39men_bn_Translation\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/function_deserialization.py:286\u001b[0m, in \u001b[0;36mrecreate_function.<locals>.restored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m   positional, keyword \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mstructured_input_signature\n\u001b[1;32m    283\u001b[0m   signature_descriptions\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    284\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mOption \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m  Keyword arguments: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m       \u001b[39m.\u001b[39mformat(index \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 286\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCould not find matching concrete function to call loaded from the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSavedModel. Got:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m  \u001b[39m\u001b[39m{\u001b[39;00m_pretty_format_positional(args)\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m  Keyword \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marguments: \u001b[39m\u001b[39m{\u001b[39;00mkwargs\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m Expected these arguments to match one of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfollowing \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(saved_function\u001b[39m.\u001b[39mconcrete_functions)\u001b[39m}\u001b[39;00m\u001b[39m option(s):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m(\u001b[39mchr\u001b[39m(\u001b[39m10\u001b[39m)\u001b[39m+\u001b[39m\u001b[39mchr\u001b[39m(\u001b[39m10\u001b[39m))\u001b[39m.\u001b[39mjoin(signature_descriptions)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"transformer_decoder\" (type TransformerDecoder).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (4 total):\n    * <tf.Tensor 'inputs:0' shape=(None, None, 256) dtype=float32>\n    * <tf.Tensor 'encoder_outputs:0' shape=(None, None, 256) dtype=float32>\n    * None\n    * False\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 2 option(s):\n\nOption 1:\n  Positional arguments (4 total):\n    * TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs')\n    * TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='encoder_outputs')\n    * TensorSpec(shape=(None, None), dtype=tf.bool, name='mask')\n    * False\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (4 total):\n    * TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='inputs')\n    * TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='encoder_outputs')\n    * TensorSpec(shape=(None, None), dtype=tf.bool, name='mask')\n    * True\n  Keyword arguments: {}\n\nCall arguments received by layer \"transformer_decoder\" (type TransformerDecoder):\n  • args=('tf.Tensor(shape=(None, None, 256), dtype=float32)',)\n  • kwargs={'encoder_outputs': 'tf.Tensor(shape=(None, None, 256), dtype=float32)', 'training': 'False'}"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('en_bn_Translation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
