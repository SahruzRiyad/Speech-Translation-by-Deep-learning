{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,LSTM,GRU,Dense,Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LSTM_NODES =256\n",
    "NUM_SENTENCES = 20000\n",
    "MAX_SENTENCE_LENGTH = 50\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples input:  4619\n",
      "num samples output:  4619\n",
      "num samples input output:  4619\n"
     ]
    }
   ],
   "source": [
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "\n",
    "count = 0\n",
    "for line in open('./ben.txt'):\n",
    "    count += 1\n",
    "\n",
    "    if count > NUM_SENTENCES:\n",
    "        break\n",
    "\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "\n",
    "    spLine = line.rstrip().split('\\t')\n",
    "    input_sentence , output = spLine[0] , spLine[1]\n",
    "    output_sentence = output + ' <eos>'\n",
    "    output_sentences_input = '<sos> ' + output\n",
    "\n",
    "    input_sentences.append(input_sentence)\n",
    "    output_sentences.append(output_sentence)\n",
    "    output_sentences_inputs.append(output_sentences_input)\n",
    "\n",
    "print(\"num samples input: \",len(input_sentences))\n",
    "print(\"num samples output: \",len(output_sentences))\n",
    "print(\"num samples input output: \",len(output_sentences_inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm getting off at the next station.\n",
      "আমি পরের স্টেশনে নেমে যাচ্ছি। <eos>\n",
      "<sos> আমি পরের স্টেশনে নেমে যাচ্ছি।\n",
      "What fun!\n",
      "কি মজা! <eos>\n",
      "<sos> কি মজা!\n",
      "I don't want Tom to find me.\n",
      "আমি চাই না টম আমাকে খুঁজে পাক। <eos>\n",
      "<sos> আমি চাই না টম আমাকে খুঁজে পাক।\n",
      "Keep quiet.\n",
      "চুপ করো। <eos>\n",
      "<sos> চুপ করো।\n",
      "Forgive Tom.\n",
      "টমকে ক্ষমা করে দাও। <eos>\n",
      "<sos> টমকে ক্ষমা করে দাও।\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x = np.random.randint(0,4349)\n",
    "    print(input_sentences[x])\n",
    "    print(output_sentences[x])\n",
    "    print(output_sentences_inputs[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Words:  1902\n",
      "Length of Longest Sequence:  20\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = Tokenizer(num_words = MAX_NUM_WORDS)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print('Total Unique Words: ',len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print('Length of Longest Sequence: ',max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the output: 3642\n",
      "Length of longest sentence in the output: 19\n"
     ]
    }
   ],
   "source": [
    "output_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "output_tokenizer.fit_on_texts(output_sentences + output_sentences_inputs)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print('Total unique words in the output: %s' % len(word2idx_outputs))\n",
    "\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Length of longest sentence in the output: %g\" % max_out_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Encoder Shape:  (4619, 20)\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 71]\n"
     ]
    }
   ],
   "source": [
    "encoder_input_sequences = pad_sequences(input_integer_seq,maxlen=max_input_len)\n",
    "\n",
    "print('Input Encoder Shape: ',encoder_input_sequences.shape)\n",
    "print(encoder_input_sequences[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(word2idx_inputs['i'])\n",
    "print(word2idx_inputs['will'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_input_sequences.shape: (4619, 19)\n",
      "decoder_input_sequences[172]: [   2  445 1177    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_input_sequences.shape:\", decoder_input_sequences.shape)\n",
    "print(\"decoder_input_sequences[172]:\", decoder_input_sequences[172])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1148\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "print(word2idx_outputs['<sos>'])\n",
    "print(word2idx_outputs['\"আপনি'])\n",
    "print(word2idx_outputs['একজন'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dictionary = dict()\n",
    "\n",
    "glove_file = open('./glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_SIZE))\n",
    "for word, index in word2idx_inputs.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "\n",
    "    if  embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11941    0.54188    0.62174   -0.10935   -0.15776   -0.013474\n",
      "  0.23946   -0.044287   0.37478   -0.049821   0.11609    0.24012\n",
      "  0.53843   -0.4148    -0.078387  -0.20494   -0.028806   0.42345\n",
      " -0.31811    0.1978     0.34817   -0.088881  -0.026402  -0.31054\n",
      " -0.08553   -0.056577  -0.051455  -0.37321   -0.20699   -0.42797\n",
      "  0.047632   0.1657    -0.16632   -0.045508   0.32539    0.31902\n",
      " -0.17114   -0.24263   -0.32311   -0.30039   -0.3664    -0.10475\n",
      "  0.27917   -0.018142  -0.065002  -0.13421    0.75376   -0.15472\n",
      "  0.13552   -0.83338    0.52732   -0.33982    0.47992    0.9676\n",
      "  0.20516   -2.4215    -0.36029   -0.092199   1.4472     0.51091\n",
      " -0.19357    0.79376   -0.42247   -0.21033    0.98025   -0.27021\n",
      "  0.29239    0.56319   -0.28621   -0.45666    0.32348   -0.22252\n",
      " -0.29755   -0.29786    0.34122   -0.0089719 -0.40418   -0.39275\n",
      " -0.87327   -0.29921    0.62069   -0.13045   -0.34651   -0.11863\n",
      " -1.6367    -0.49879    0.36034    0.042055  -0.64994   -0.26185\n",
      "  0.16331   -0.090286  -0.43469    0.15578   -0.49886    0.35222\n",
      " -0.38682   -0.38046   -0.042247   0.35155  ]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_dictionary['yet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11941     0.54188001  0.62173998 -0.10935    -0.15775999 -0.013474\n",
      "  0.23946001 -0.044287    0.37478    -0.049821    0.11609     0.24011999\n",
      "  0.53842998 -0.41479999 -0.078387   -0.20494001 -0.028806    0.42344999\n",
      " -0.31810999  0.1978      0.34817001 -0.088881   -0.026402   -0.31053999\n",
      " -0.08553    -0.056577   -0.051455   -0.37321001 -0.20699    -0.42796999\n",
      "  0.047632    0.1657     -0.16632    -0.045508    0.32539001  0.31902\n",
      " -0.17114    -0.24263    -0.32311001 -0.30039001 -0.3664     -0.10475\n",
      "  0.27917001 -0.018142   -0.065002   -0.13421001  0.75375998 -0.15471999\n",
      "  0.13552    -0.83337998  0.52732003 -0.33982     0.47992     0.96759999\n",
      "  0.20516001 -2.42149997 -0.36028999 -0.092199    1.44719994  0.51090997\n",
      " -0.19357     0.79376    -0.42247    -0.21032999  0.98025    -0.27021\n",
      "  0.29238999  0.56318998 -0.28621    -0.45666     0.32348001 -0.22251999\n",
      " -0.29754999 -0.29786     0.34121999 -0.0089719  -0.40417999 -0.39274999\n",
      " -0.87326998 -0.29921001  0.62068999 -0.13045    -0.34650999 -0.11863\n",
      " -1.63670003 -0.49879     0.36034     0.042055   -0.64994001 -0.26185\n",
      "  0.16331001 -0.090286   -0.43469     0.15578    -0.49886     0.35222\n",
      " -0.38681999 -0.38045999 -0.042247    0.35155001]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix[184])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_targets_one_hot = np.zeros((\n",
    "        len(input_sentences),\n",
    "        max_out_len,\n",
    "        num_words_output\n",
    "    ),\n",
    "    dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4619, 19, 3643)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_targets_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(decoder_input_sequences):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 13:02:06.973495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 13:02:07.149596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 13:02:07.150305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 13:02:07.158660: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-20 13:02:07.159262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 13:02:07.160060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 13:02:07.160450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 13:02:08.517399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 13:02:08.517667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 13:02:08.517864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 13:02:08.518658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3396 MB memory:  -> device: 0, name: NVIDIA GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs_placeholder = Input(shape=(max_input_len,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = LSTM(LSTM_NODES, return_state=True)\n",
    "\n",
    "encoder_outputs, h, c = encoder(x)\n",
    "encoder_states = [h, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs_placeholder = Input(shape=(max_out_len,))\n",
    "\n",
    "decoder_embedding = Embedding(num_words_output, LSTM_NODES)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "decoder_lstm = LSTM(LSTM_NODES, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs_placeholder,\n",
    "  decoder_inputs_placeholder], decoder_outputs)\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model_plot4a.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 13:10:07.095205: E tensorflow/stream_executor/cuda/cuda_dnn.cc:361] Loaded runtime CuDNN library: 8.0.5 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2022-08-20 13:10:07.096771: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at cudnn_rnn_ops.cc:1556 : UNKNOWN: Fail to find the dnn implementation.\n",
      "2022-08-20 13:10:14.819208: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.90MiB (rounded to 17719552)requested by op SameWorkerRecvDone\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-08-20 13:10:14.819328: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2022-08-20 13:10:14.819373: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 35, Chunks in use: 35. 8.8KiB allocated for chunks. 8.8KiB in use in bin. 172B client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819403: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 2, Chunks in use: 2. 1.5KiB allocated for chunks. 1.5KiB in use in bin. 1.4KiB client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819430: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819456: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819485: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 8, Chunks in use: 8. 33.0KiB allocated for chunks. 33.0KiB in use in bin. 32.8KiB client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819513: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 4, Chunks in use: 3. 46.8KiB allocated for chunks. 36.8KiB in use in bin. 33.5KiB client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819541: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 1, Chunks in use: 1. 24.8KiB allocated for chunks. 24.8KiB in use in bin. 14.2KiB client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819565: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819591: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 1, Chunks in use: 0. 106.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819615: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819668: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 3, Chunks in use: 2. 1.14MiB allocated for chunks. 800.0KiB in use in bin. 800.0KiB client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819723: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 5, Chunks in use: 3. 3.62MiB allocated for chunks. 2.00MiB in use in bin. 1.84MiB client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819798: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 11, Chunks in use: 10. 11.59MiB allocated for chunks. 10.58MiB in use in bin. 10.19MiB client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819845: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 5, Chunks in use: 5. 17.79MiB allocated for chunks. 17.79MiB in use in bin. 17.79MiB client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819883: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819926: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 1, Chunks in use: 0. 11.34MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-08-20 13:10:14.819968: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-08-20 13:10:14.820010: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-08-20 13:10:14.820049: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-08-20 13:10:14.820114: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-08-20 13:10:14.820168: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 3, Chunks in use: 3. 3.27GiB allocated for chunks. 3.27GiB in use in bin. 3.21GiB client-requested in use in bin.\n",
      "2022-08-20 13:10:14.820213: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 16.90MiB was 16.00MiB, Chunk State: \n",
      "2022-08-20 13:10:14.820246: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 3561684992\n",
      "2022-08-20 13:10:14.821421: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5016a0000 of size 1280 next 1\n",
      "2022-08-20 13:10:14.821499: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5016a0500 of size 256 next 2\n",
      "2022-08-20 13:10:14.821527: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5016a0600 of size 256 next 3\n",
      "2022-08-20 13:10:14.821549: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5016a0700 of size 761344 next 4\n",
      "2022-08-20 13:10:14.821571: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175a500 of size 256 next 6\n",
      "2022-08-20 13:10:14.821591: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175a600 of size 256 next 7\n",
      "2022-08-20 13:10:14.821625: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175a700 of size 256 next 5\n",
      "2022-08-20 13:10:14.821662: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175a800 of size 256 next 8\n",
      "2022-08-20 13:10:14.821704: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175a900 of size 256 next 11\n",
      "2022-08-20 13:10:14.821740: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175aa00 of size 256 next 15\n",
      "2022-08-20 13:10:14.821762: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175ab00 of size 256 next 21\n",
      "2022-08-20 13:10:14.821782: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175ac00 of size 256 next 26\n",
      "2022-08-20 13:10:14.821803: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175ad00 of size 256 next 14\n",
      "2022-08-20 13:10:14.821827: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175ae00 of size 256 next 13\n",
      "2022-08-20 13:10:14.821847: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175af00 of size 256 next 38\n",
      "2022-08-20 13:10:14.821869: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175b000 of size 256 next 39\n",
      "2022-08-20 13:10:14.821890: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175b100 of size 256 next 40\n",
      "2022-08-20 13:10:14.821910: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175b200 of size 256 next 49\n",
      "2022-08-20 13:10:14.821931: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175b300 of size 256 next 50\n",
      "2022-08-20 13:10:14.821951: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175b400 of size 256 next 51\n",
      "2022-08-20 13:10:14.821971: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175b500 of size 256 next 52\n",
      "2022-08-20 13:10:14.821992: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175b600 of size 256 next 53\n",
      "2022-08-20 13:10:14.822012: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175b700 of size 256 next 54\n",
      "2022-08-20 13:10:14.822033: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175b800 of size 256 next 55\n",
      "2022-08-20 13:10:14.822054: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175b900 of size 256 next 56\n",
      "2022-08-20 13:10:14.822075: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175ba00 of size 256 next 17\n",
      "2022-08-20 13:10:14.822097: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175bb00 of size 4096 next 18\n",
      "2022-08-20 13:10:14.822117: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175cb00 of size 256 next 30\n",
      "2022-08-20 13:10:14.822138: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175cc00 of size 256 next 31\n",
      "2022-08-20 13:10:14.822158: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175cd00 of size 256 next 32\n",
      "2022-08-20 13:10:14.822178: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175ce00 of size 256 next 33\n",
      "2022-08-20 13:10:14.822198: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175cf00 of size 256 next 35\n",
      "2022-08-20 13:10:14.822218: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175d000 of size 256 next 36\n",
      "2022-08-20 13:10:14.822237: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175d100 of size 256 next 37\n",
      "2022-08-20 13:10:14.822257: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175d200 of size 256 next 24\n",
      "2022-08-20 13:10:14.822277: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175d300 of size 4096 next 27\n",
      "2022-08-20 13:10:14.822298: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 50175e300 of size 14592 next 29\n",
      "2022-08-20 13:10:14.822318: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 501761c00 of size 10240 next 88\n",
      "2022-08-20 13:10:14.822339: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 501764400 of size 256 next 87\n",
      "2022-08-20 13:10:14.822359: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 501764500 of size 779008 next 9\n",
      "2022-08-20 13:10:14.822380: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 501822800 of size 409600 next 10\n",
      "2022-08-20 13:10:14.822400: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 501886800 of size 409600 next 41\n",
      "2022-08-20 13:10:14.822421: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5018ea800 of size 4096 next 43\n",
      "2022-08-20 13:10:14.822441: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5018eb800 of size 4096 next 46\n",
      "2022-08-20 13:10:14.822461: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5018ec800 of size 14592 next 48\n",
      "2022-08-20 13:10:14.822482: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5018f0100 of size 256 next 64\n",
      "2022-08-20 13:10:14.822502: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5018f0200 of size 25344 next 76\n",
      "2022-08-20 13:10:14.822524: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5018f6500 of size 4352 next 63\n",
      "2022-08-20 13:10:14.822559: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5018f7600 of size 4096 next 68\n",
      "2022-08-20 13:10:14.822608: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5018f8600 of size 4096 next 77\n",
      "2022-08-20 13:10:14.822646: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5018f9600 of size 578048 next 16\n",
      "2022-08-20 13:10:14.822680: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 501986800 of size 1048576 next 12\n",
      "2022-08-20 13:10:14.822741: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 501a86800 of size 1048576 next 23\n",
      "2022-08-20 13:10:14.822787: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 501b86800 of size 1048576 next 22\n",
      "2022-08-20 13:10:14.822814: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 501c86800 of size 1048576 next 42\n",
      "2022-08-20 13:10:14.822835: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 501d86800 of size 1048576 next 44\n",
      "2022-08-20 13:10:14.822869: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 501e86800 of size 1048576 next 45\n",
      "2022-08-20 13:10:14.822917: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 501f86800 of size 761344 next 81\n",
      "2022-08-20 13:10:14.822953: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 502040600 of size 1456640 next 20\n",
      "2022-08-20 13:10:14.822988: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5021a4000 of size 3730432 next 19\n",
      "2022-08-20 13:10:14.823021: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 502532c00 of size 1245184 next 57\n",
      "2022-08-20 13:10:14.823052: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 502662c00 of size 372736 next 75\n",
      "2022-08-20 13:10:14.823086: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5026bdc00 of size 4864 next 89\n",
      "2022-08-20 13:10:14.823120: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 5026bef00 of size 109056 next 86\n",
      "2022-08-20 13:10:14.823152: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5026d9900 of size 8448 next 84\n",
      "2022-08-20 13:10:14.823184: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 5026dba00 of size 1067264 next 83\n",
      "2022-08-20 13:10:14.823217: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5027e0300 of size 768 next 66\n",
      "2022-08-20 13:10:14.823258: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5027e0600 of size 768 next 91\n",
      "2022-08-20 13:10:14.823290: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 5027e0900 of size 921344 next 28\n",
      "2022-08-20 13:10:14.823322: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5028c1800 of size 3730432 next 25\n",
      "2022-08-20 13:10:14.823361: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 502c50400 of size 1150940416 next 34\n",
      "2022-08-20 13:10:14.823394: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 5475ef900 of size 3730432 next 47\n",
      "2022-08-20 13:10:14.823424: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 54797e500 of size 3730432 next 67\n",
      "2022-08-20 13:10:14.823463: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 547d0d100 of size 1048576 next 60\n",
      "2022-08-20 13:10:14.823496: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 547e0d100 of size 3730432 next 70\n",
      "2022-08-20 13:10:14.823526: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 54819bd00 of size 1048576 next 61\n",
      "2022-08-20 13:10:14.823559: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 54829bd00 of size 256 next 73\n",
      "2022-08-20 13:10:14.823589: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 54829be00 of size 11891712 next 65\n",
      "2022-08-20 13:10:14.823620: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 548df3200 of size 1150940416 next 71\n",
      "2022-08-20 13:10:14.823663: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 58d792700 of size 1211881728 next 18446744073709551615\n",
      "2022-08-20 13:10:14.823701: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2022-08-20 13:10:14.823752: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 35 Chunks of size 256 totalling 8.8KiB\n",
      "2022-08-20 13:10:14.823810: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 768 totalling 1.5KiB\n",
      "2022-08-20 13:10:14.823852: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-08-20 13:10:14.823893: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 4096 totalling 24.0KiB\n",
      "2022-08-20 13:10:14.823931: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 4352 totalling 4.2KiB\n",
      "2022-08-20 13:10:14.823968: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 4864 totalling 4.8KiB\n",
      "2022-08-20 13:10:14.824007: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 8448 totalling 8.2KiB\n",
      "2022-08-20 13:10:14.824047: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 14592 totalling 28.5KiB\n",
      "2022-08-20 13:10:14.824087: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 25344 totalling 24.8KiB\n",
      "2022-08-20 13:10:14.824128: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 409600 totalling 800.0KiB\n",
      "2022-08-20 13:10:14.824175: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 578048 totalling 564.5KiB\n",
      "2022-08-20 13:10:14.824214: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 761344 totalling 1.45MiB\n",
      "2022-08-20 13:10:14.824264: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 8 Chunks of size 1048576 totalling 8.00MiB\n",
      "2022-08-20 13:10:14.824351: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1245184 totalling 1.19MiB\n",
      "2022-08-20 13:10:14.824425: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1456640 totalling 1.39MiB\n",
      "2022-08-20 13:10:14.824466: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 5 Chunks of size 3730432 totalling 17.79MiB\n",
      "2022-08-20 13:10:14.824493: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 1150940416 totalling 2.14GiB\n",
      "2022-08-20 13:10:14.824554: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1211881728 totalling 1.13GiB\n",
      "2022-08-20 13:10:14.824605: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 3.30GiB\n",
      "2022-08-20 13:10:14.824647: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 3561684992 memory_limit_: 3561684992 available bytes: 0 curr_region_allocation_bytes_: 7123369984\n",
      "2022-08-20 13:10:14.825671: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                      3561684992\n",
      "InUse:                      3546533632\n",
      "MaxInUse:                   3551251200\n",
      "NumAllocs:                         368\n",
      "MaxAllocSize:               1211881728\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-08-20 13:10:14.825811: W tensorflow/core/common_runtime/bfc_allocator.cc:474] ***************************************************************************************************x\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nFail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[model/lstm/PartitionedCall]] [Op:__inference_train_function_5790]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/riad/Documents/Speech Translation/NLP_Text_to_Text.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/riad/Documents/Speech%20Translation/NLP_Text_to_Text.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/riad/Documents/Speech%20Translation/NLP_Text_to_Text.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     [encoder_input_sequences, decoder_input_sequences],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/riad/Documents/Speech%20Translation/NLP_Text_to_Text.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     decoder_targets_one_hot,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/riad/Documents/Speech%20Translation/NLP_Text_to_Text.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/riad/Documents/Speech%20Translation/NLP_Text_to_Text.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/riad/Documents/Speech%20Translation/NLP_Text_to_Text.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/riad/Documents/Speech%20Translation/NLP_Text_to_Text.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nFail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[model/lstm/PartitionedCall]] [Op:__inference_train_function_5790]"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    [encoder_input_sequences, decoder_input_sequences],\n",
    "    decoder_targets_one_hot,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
